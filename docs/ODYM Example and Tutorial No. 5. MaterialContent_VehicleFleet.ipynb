{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ODYM Example no. 5. Estimating the material content of the global vehicle fleet\n",
    "\n",
    "ODYM was designed to handle extensive MFA systems by covering multiple aspects (time, age-cohort, region, material, chemical elements, processes, goods, components, ...) in a systematic manner. Its data format is used to structure and store input data, its software structure determines how the information is organised in the computer, and its application scripts provide a working environment for conducting reproducible dynamic MFA research with comprehensive and multi-aspect systems.\n",
    "\n",
    "This example shows a fully-fledged application of ODYM to estimate the material composition of the global passenger vehicle fleet in 2017, covering 130 countries, 25 age-cohorts, and 25 materials. The application is controlled by a config file, reads the model parameters in standard format, performs the model computations and a Monte-Carlo simulation of the uncertainties stemming from vehicle lifetime and material composition, performs automatic mass balance checks, and stores the model procedures in a log file.\n",
    "\n",
    "The research questions asked are: __How big is the material stock currently embodied in the global passenger vehicle fleet, and when will this material become available for recycling?__\n",
    "\n",
    "To answer these questions a dynamic material flow analysis of the global passenger vehicle fleet and the waste management industries is performed.\n",
    "\n",
    "The dynamic MFA model has the following indices:\n",
    "+ t: time (1990-2017)\n",
    "+ c: age-cohort (1990-2017)\n",
    "+ r: region (130 countries accounting for most of the global vehicle fleet)\n",
    "+ g: good (passenger vehicle)\n",
    "+ p: process (vehicle markets, use phase, waste management industries, scrap markets)\n",
    "+ m: engineering materials (25)\n",
    "+ e: chemical elements (all)\n",
    "+ w: waste types (steel, Al, Cu scrap, plastics, glass, and other waste)\n",
    "\n",
    "The system definition of the model is given in the figure below. The data availability limits the temporal scope to 2017. The figure also shows the aspects of the different system variables. The total registration of vehicles, for example, is broken down into individual materials, whereas the flow of deregistered vehicles is broken down into regions, age-cohorts, and materials.\n",
    "\n",
    "<img src=\"Images/ODYM_Tutorial5_SysDef.png\" width=\"850\" height=\"290\" alt=\"ODYM_Tutorial5 System Definition\">\n",
    "\n",
    "The model equations are as follows:\n",
    "\n",
    "1) inflow-driven dynamic stock model, where _F12_ is the historic inflow, _Sf_ is the survival function of the age-cohort (1-sum(pdf of discard)), and _S2_ is the stock:\n",
    "$$S_2(t,c,r,g) = F_{1-2}(c,r,g)\\cdot Sf(t,c,r,g)$$\n",
    "\n",
    "2) Calculation of difference between inflow-driven stock (covering only the age-cohorts 2005-2017 due to data availability) and the 2015 reported stock and distribution of the difference to the years 1990-2005 (constant inflow assumed for these years)\n",
    "\n",
    "3) Calculation of material composition of the fleet _S2_ with\n",
    "\n",
    "$$S_2(t,c,r,g,m) = \\mu(c,r,g,m)\\cdot S_2(t,c,r,g)$$\n",
    "\n",
    "4) Estimation of available future end-of-life vehicle scrap _F34_ with\n",
    "$$F_{3-4}(r,g,w,m) = \\sum_{t,c}EoL_eff(r,g,m,w)\\cdot M(t,c,r,g,m)$$\n",
    "\n",
    "The remaining system variables are calculated by mass balance.\n",
    "\n",
    "__Model choice:__ Because the system covers region, material, waste, and chemical element aspects and a dynamic stock model, a simple calculation in Excel would be too laborious and the potential for testing and quick re-use of data and programming would be limited. Instead, the ODYM framework is chosen to structure the model data and calculations.\n",
    "\n",
    "### 1) Load ODYM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (1906772829.py <<module>>): ### 1. - Initialize.\n"
     ]
    }
   ],
   "source": [
    "# Load a local copy of the current ODYM branch:\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import openpyxl\n",
    "import xlwt\n",
    "import pylab\n",
    "from copy import deepcopy\n",
    "import logging as log\n",
    "\n",
    "# For Ipython Notebook only\n",
    "%matplotlib inline\n",
    "\n",
    "# add ODYM module directory to system path, relative\n",
    "MainPath = os.getcwd().split('/docs')[0] # optionally removing the /docs part makes the code work both as notebook and python script (e.g. nbconvert --to script path_to_notebook)\n",
    "sys.path.insert(0, MainPath)\n",
    "\n",
    "# add ODYM module directory to system path, absolute\n",
    "sys.path.insert(0, os.path.join(MainPath, 'odym', 'modules'))\n",
    "\n",
    "# Specify path to dynamic stock model and to datafile, absolute\n",
    "DataPath = os.path.join(MainPath, 'docs', 'Files')\n",
    "\n",
    "\n",
    "import ODYM_Classes as msc # import the ODYM class file\n",
    "import ODYM_Functions as msf # import the ODYM function file\n",
    "import dynamic_stock_model as dsm # import the dynamic stock model library\n",
    "\n",
    "# Initialize loggin routine\n",
    "log_verbosity = eval(\"log.DEBUG\")\n",
    "log_filename = 'LogFileTest.md'\n",
    "[Mylog, console_log, file_log] = msf.function_logger(log_filename, os.getcwd(),\n",
    "                                                     log_verbosity, log_verbosity)\n",
    "Mylog.info('### 1. - Initialize.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jankle/odym_aviation/docs'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load Config file and read model control parameters\n",
    "\n",
    "Now using the build-in methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mylog.info('### 2 - Load Config file and read model control parameters')\n",
    "#Read main script parameters\n",
    "#Load project-specific config file\n",
    "ProjectSpecs_Name_ConFile = 'ODYM_Config_Tutorial5.xlsx'\n",
    "Model_Configfile = openpyxl.load_workbook(os.path.join(DataPath, ProjectSpecs_Name_ConFile), data_only=True)\n",
    "ScriptConfig = {'Model Setting': Model_Configfile['Config'].cell(4,4).value, 'Version of master classification':'ODYM_Classifications_Master_Tutorial'}\n",
    "Model_Configsheet = Model_Configfile['Setting_' + ScriptConfig['Model Setting']]\n",
    "IT_Aspects,IT_Description,IT_Dimension,IT_Classification,IT_Selector,IT_IndexLetter,PL_Names,PL_Description,PL_Version,PL_IndexStructure,PL_IndexMatch,PL_IndexLayer,PL_SubFolder,PL_ProxyCode,PL_ProcMethod,PL_UpdateOverwrite,PrL_Number,PrL_Name,PrL_Comment,PrL_Type,ScriptConfig = msf.ParseConfigFile(Model_Configsheet,ScriptConfig,Mylog)\n",
    "\n",
    "# and classification\n",
    "Classfile  = openpyxl.load_workbook(os.path.join(DataPath, \n",
    "                                             str(ScriptConfig['Version of master classification']) \\\n",
    "                                             + '.xlsx'), data_only=True)\n",
    "Classsheet = Classfile['MAIN_Table']\n",
    "MasterClassification = msf.ParseClassificationFile_Main(Classsheet, Mylog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Define model classifications and select items for model classifications according to information provided by config file.')\n",
    "ModelClassification  = {} # Dict of model classifications\n",
    "for m in range(0,len(IT_Aspects)):\n",
    "    ModelClassification[IT_Aspects[m]] = deepcopy(MasterClassification[IT_Classification[m]])\n",
    "    EvalString = msf.EvalItemSelectString(IT_Selector[m],len(ModelClassification[IT_Aspects[m]].Items))\n",
    "    if EvalString.find(':') > -1: # range of items is taken\n",
    "        RangeStart = int(EvalString[0:EvalString.find(':')])\n",
    "        RangeStop  = int(EvalString[EvalString.find(':')+1::])\n",
    "        ModelClassification[IT_Aspects[m]].Items = ModelClassification[IT_Aspects[m]].Items[RangeStart:RangeStop]           \n",
    "    elif EvalString.find('[') > -1: # selected items are taken\n",
    "        ModelClassification[IT_Aspects[m]].Items = \\\n",
    "            [ModelClassification[IT_Aspects[m]].Items[i] for i in eval(EvalString)]\n",
    "    elif EvalString == 'all':\n",
    "        None\n",
    "    else:\n",
    "        Mylog.info('ITEM SELECT ERROR for aspect ' + IT_Aspects[m] + ' were found in datafile.</br>')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block creates the index table for the MFA system and parses all parameter files specified into the parameter dictionary ParameterDict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model index table and parameter dictionary\n",
    "Model_Time_Start = int(min(ModelClassification['Time'].Items))\n",
    "Model_Time_End   = int(max(ModelClassification['Time'].Items))\n",
    "Model_Duration   = Model_Time_End - Model_Time_Start\n",
    "\n",
    "print('Define index table dataframe.')\n",
    "IndexTable = pd.DataFrame({'Aspect'        : IT_Aspects, # 'Time' and 'Element' must be present!\n",
    "                           'Description'   : IT_Description,\n",
    "                           'Dimension'     : IT_Dimension,\n",
    "                           'Classification': [ModelClassification[Aspect] for Aspect in IT_Aspects],\n",
    "                           # Unique one letter (upper or lower case) indices to be used later for calculations.\n",
    "                           'IndexLetter'   : IT_IndexLetter}) \n",
    "\n",
    "# Default indexing of IndexTable, other indices are produced on the fly\n",
    "IndexTable.set_index('Aspect', inplace = True) \n",
    "\n",
    "# Add indexSize to IndexTable:\n",
    "IndexTable['IndexSize'] = \\\n",
    "    pd.Series([len(IndexTable.Classification[i].Items) for i in range(0,len(IndexTable.IndexLetter))], index=IndexTable.index)\n",
    "\n",
    "# list of the classifications used for each indexletter\n",
    "IndexTable_ClassificationNames = [IndexTable.Classification[i].Name for i in range(0,len(IndexTable.IndexLetter))] \n",
    "\n",
    "#Define shortcuts for the most important index sizes:\n",
    "Nt = len(IndexTable.Classification[IndexTable.index.get_loc('Time')].Items)\n",
    "NR = len(IndexTable.Classification[IndexTable.set_index('IndexLetter').index.get_loc('r')].Items)\n",
    "NG = len(IndexTable.Classification[IndexTable.set_index('IndexLetter').index.get_loc('g')].Items)\n",
    "NM = len(IndexTable.Classification[IndexTable.set_index('IndexLetter').index.get_loc('m')].Items)\n",
    "print('Read model data and parameters.')\n",
    "\n",
    "ParameterDict = {}\n",
    "for mo in range(0,len(PL_Names)):\n",
    "    ParPath = os.path.join(DataPath,PL_Version[mo])\n",
    "    print('Reading parameter ' + PL_Names[mo])\n",
    "    # Do not change order of parameters handed over to function!\n",
    "    # def ReadParameterXLSX(ParPath, ThisPar, ThisParIx, \n",
    "    #                       IndexMatch, ThisParLayerSel, ThisParProcMethod, \n",
    "    #                       MasterClassification,IndexTable, IndexTable_ClassificationNames, \n",
    "    #                       ScriptConfig, Mylog, ParseUncertainty):\n",
    "    MetaData, Values, Uncertainty = msf.ReadParameterXLSX(\n",
    "        ParPath, PL_Names[mo], PL_IndexStructure[mo], \n",
    "        PL_IndexMatch[mo], PL_IndexLayer[mo], '[\"none\"]',\n",
    "        MasterClassification,         IndexTable, IndexTable_ClassificationNames, \n",
    "        ScriptConfig, \n",
    "        Mylog, ParseUncertainty = True) \n",
    "    ParameterDict[PL_Names[mo]] = msc.Parameter(Name = MetaData['Dataset_Name'], \n",
    "                                                ID = MetaData['Dataset_ID'], \n",
    "                                                UUID = MetaData['Dataset_UUID'],\n",
    "                                                P_Res = None,\n",
    "                                                MetaData = MetaData,\n",
    "                                                Indices = PL_IndexStructure[mo], \n",
    "                                                Values=Values, \n",
    "                                                Uncert=Uncertainty,\n",
    "                                                Unit = MetaData['Dataset_Unit'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifications for the different parameter aspects specified in all the parameter files must be the same as specified in the config file for the model run. The resolution can differ, however: The parameter files can contain classification items not selected for the current model run, and the model run can contain classification items for which no data are present, in which case the value remains at zero.\n",
    "\n",
    "In the report returned by msf.ReadParameterV2 above, the function returns the number of values read from each parameter file and the number of values assigned to the parameter arrays in the parameter dictionary.\n",
    "\n",
    "Not all values are assigned (e.g., the vehicle stock in the parameter file is given for 2015 only) and more values than needed for the parameter files may be present (e.g. vehicle registration and vehicle stock data are present for more countries than selected for the model run).\n",
    "\n",
    "Next, we define proxies to fill data gaps. This proxy-filling can be done in the parameter files, if general, but should be done in the model here, if model-specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate lifetime, given for 2010 age-cohort, for all age-cohorts\n",
    "ParameterDict['ODYM_Tutorial5_VehicleLifetime'].Values[0,0,:,:] = np.einsum('r,c->rc',ParameterDict['ODYM_Tutorial5_VehicleLifetime'].Values[0,0,:,20],np.ones(Nt))\n",
    "\n",
    "for m in range(0,NR): # Replicate uncertainty (not very elegantly)\n",
    "    for n in range(0,Nt):\n",
    "        ParameterDict['ODYM_Tutorial5_VehicleLifetime'].Uncert[m*Nt +n] = ParameterDict['ODYM_Tutorial5_VehicleLifetime'].Uncert[m*Nt+20]\n",
    "\n",
    "\n",
    "# Replicate vehicle material content for all countries and age-cohorts\n",
    "ParameterDict['ODYM_Tutorial5_VehicleMaterialContent'].Values[:,0,:,:] = np.einsum('m,rc->mrc',ParameterDict['ODYM_Tutorial5_VehicleMaterialContent'].Values[:,0,0,20],np.ones((NR,Nt)))\n",
    "\n",
    "for m in range(0,NM): # Replicate uncertainty (not very elegantly)\n",
    "    for r in range(0,NR):\n",
    "        for t in range(0,Nt):\n",
    "            ParameterDict['ODYM_Tutorial5_VehicleMaterialContent'].Uncert[m*Nt*NR + r*Nt +t] = ParameterDict['ODYM_Tutorial5_VehicleMaterialContent'].Uncert[m*Nt*NR +20]\n",
    "\n",
    "\n",
    "# The missing years (prior to 2005) for the vehicle registration are estimated later/\n",
    "# The stock is only given for 2015 as a refernce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Define MFA system \n",
    "With the index table and parameter dictionary defined, we can now define the MFA system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mylog.info('### 4 - Define MFA system')\n",
    "print('Define MFA system and processes.')\n",
    "\n",
    "PassengerVehicleFleet_MFA_System = msc.MFAsystem(Name = 'Materials_GlobalPassengerVehicleFleet', \n",
    "                      Geogr_Scope = 'World', \n",
    "                      Unit = 'Mt', \n",
    "                      ProcessList = [], \n",
    "                      FlowDict = {}, \n",
    "                      StockDict = {},\n",
    "                      ParameterDict = ParameterDict, \n",
    "                      Time_Start = Model_Time_Start, \n",
    "                      Time_End = Model_Time_End, \n",
    "                      IndexTable = IndexTable, \n",
    "                      Elements = IndexTable.loc['Element'].Classification.Items, \n",
    "                      Graphical = None) # Initialize MFA system\n",
    "                      \n",
    "# Check Validity of index tables:\n",
    "# returns true if dimensions are OK and time index is present and element list is not empty\n",
    "PassengerVehicleFleet_MFA_System.IndexTableCheck() \n",
    "\n",
    "# Add processes to system\n",
    "for m in range(0, len(PrL_Number)):\n",
    "    PassengerVehicleFleet_MFA_System.ProcessList.append(msc.Process(Name = PrL_Name[m], ID   = PrL_Number[m]))\n",
    "    \n",
    "# Define system variables: 6 flows.     \n",
    "PassengerVehicleFleet_MFA_System.FlowDict['F_0_1'] = msc.Flow(Name = 'Passenger vehicle production', P_Start = 0,\n",
    "                                                  P_End = 1, Indices = 't,g,m,e',\n",
    "                                                  Values=None, Uncert=None, Color = None,\n",
    "                                                  ID = None, UUID = None)\n",
    "PassengerVehicleFleet_MFA_System.FlowDict['F_1_2'] = msc.Flow(Name = 'New registration of vehicles', P_Start = 1, \n",
    "                                                  P_End = 2, Indices = 't,g,r,m,e', \n",
    "                                                  Values=None, Uncert=None, Color = None, \n",
    "                                                  ID = None, UUID = None)\n",
    "\n",
    "PassengerVehicleFleet_MFA_System.FlowDict['F_2_3'] = msc.Flow(Name = 'Scrapping of vehicles', P_Start = 2, \n",
    "                                                  P_End = 3, Indices = 't,c,g,r,m,e', \n",
    "                                                  Values=None, Uncert=None, Color = None, \n",
    "                                                  ID = None, UUID = None)\n",
    "\n",
    "PassengerVehicleFleet_MFA_System.FlowDict['F_3_4'] = msc.Flow(Name = 'Vehicle scrap', P_Start = 3, \n",
    "                                                  P_End = 4, Indices = 't,w,m,e', \n",
    "                                                  Values=None, Uncert=None, Color = None, \n",
    "                                                  ID = None, UUID = None)\n",
    "\n",
    "PassengerVehicleFleet_MFA_System.FlowDict['F_3_0'] = msc.Flow(Name = 'Recovery losses', P_Start = 3, \n",
    "                                                  P_End = 0, Indices = 't,m,e', \n",
    "                                                  Values=None, Uncert=None, Color = None, \n",
    "                                                  ID = None, UUID = None)\n",
    "\n",
    "PassengerVehicleFleet_MFA_System.FlowDict['F_4_0'] = msc.Flow(Name = 'Vehicle scrap supply', P_Start = 4, \n",
    "                                                  P_End = 0, Indices = 't,w,m,e', \n",
    "                                                  Values=None, Uncert=None, Color = None, \n",
    "                                                  ID = None, UUID = None)\n",
    "\n",
    "# Define system variables: 1 stock and 1 stock change:\n",
    "PassengerVehicleFleet_MFA_System.StockDict['S_2']  = msc.Stock(Name = 'In-use stock', P_Res = 2, Type = 0,\n",
    "                                                  Indices = 't,c,g,r,m,e', Values=None, Uncert=None,\n",
    "                                                  ID = None, UUID = None)\n",
    "\n",
    "PassengerVehicleFleet_MFA_System.StockDict['dS_2']  = msc.Stock(Name = 'Net in-use stock change', P_Res = 2, Type = 1,\n",
    "                                                  Indices = 't,g,r,m,e', Values=None, Uncert=None,\n",
    "                                                  ID = None, UUID = None)\n",
    "\n",
    "PassengerVehicleFleet_MFA_System.Initialize_StockValues() # Assign empty arrays to stocks according to dimensions.\n",
    "PassengerVehicleFleet_MFA_System.Initialize_FlowValues() # Assign empty arrays to flows according to dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PassengerVehicleFleet_MFA_System.IndexTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PassengerVehicleFleet_MFA_System.ParameterDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PassengerVehicleFleet_MFA_System.ProcessList)\n",
    "print([i.Name for i in PassengerVehicleFleet_MFA_System.ProcessList])\n",
    "print([i.ID for i in PassengerVehicleFleet_MFA_System.ProcessList])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5) Building and solving the MFA model, without consideration of parameter uncertainty\n",
    "\n",
    "With the parameter loaded into the MFA system structure the system model can now be built and solved as shown in the previous tutorials.\n",
    "\n",
    "In a first step, the dynamic stock model for the passenger vehicle fleet is computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mylog.info('### 5 - Building and solving the MFA model, without consideration of parameter uncertainty')\n",
    "# 1) Determine vehicle stock and outflow by age-cohort from registration data. These calculations are done outside of the MFA system, \n",
    "# as we are not yet on the material level but at the product level.\n",
    "# The 2015 stock is calculated and compared to the actual reported stock.\n",
    "\n",
    "Dyn_MFA_EstimatedVehicleStock2015 = np.zeros((NR)) # determined for calibration purposes.\n",
    "GlobalVehicleStock_TimeSeries     = np.zeros((Nt,Nt,NG,NR)) # determined for visualisation and verification purposes and for the Monte-Carlo simulation.\n",
    "GlobalEoL_Vehicles_TimeSeries     = np.zeros((Nt,Nt,NG,NR)) # determined for visualisation and verification purposes and for the Monte-Carlo simulation.\n",
    "print('Solving dynamic stock model of the passenger vehicle fleet for: ')\n",
    "for region in np.arange(0,NR):\n",
    "    # Determine lifetime distribution from uncertainty string (of first age-cohort, as all age-cohorts have the same lifetime here)\n",
    "    UncParts   = ParameterDict['ODYM_Tutorial5_VehicleLifetime'].Uncert[region*Nt].split(';') # parse uncertainty string\n",
    "    if int(UncParts[0]) == 3: # Define dictionary for normally distributed lifetime\n",
    "        LT = {'Type': 'Normal', 'Mean': [float(UncParts[1])],'StdDev': [float(UncParts[2])]}\n",
    "    if int(UncParts[0]) == 8: # Define dictionary for Weibull-distributed lifetime\n",
    "        LT = {'Type': 'Weibull', 'Scale': [1/float(UncParts[2])],'Shape': [float(UncParts[3])]}    \n",
    "        \n",
    "    # 1a) Loop over all regions to determine inflow-driven stock of vehicles, with pre 2005 age-cohorts absent\n",
    "    print(IndexTable.Classification[IndexTable.set_index('IndexLetter').index.get_loc('r')].Items[region])\n",
    "    # Create helper DSM for computing the dynamic stock model:\n",
    "    DSM_Inflow = dsm.DynamicStockModel(t = np.array(IndexTable.Classification[IndexTable.index.get_loc('Time')].Items),\n",
    "                                       i = PassengerVehicleFleet_MFA_System.ParameterDict['ODYM_Tutorial5_VehicleNewRegistration'].Values[0,region,:,0], \n",
    "                                       lt = LT)\n",
    "    \n",
    "    Stock_by_cohort = DSM_Inflow.compute_s_c_inflow_driven()\n",
    "    #print(Stock_by_cohort.shape)\n",
    "    O_C = DSM_Inflow.compute_o_c_from_s_c()\n",
    "    #print(O_C.shape)\n",
    "    S = DSM_Inflow.compute_stock_total()\n",
    "    #print(S.shape)\n",
    "    DS = DSM_Inflow.compute_stock_change()\n",
    "    #print(DS.shape)\n",
    "    Dyn_MFA_EstimatedVehicleStock2015[region] = S[25]\n",
    "    \n",
    "    # Calibration: the following countries got their lifetime adjusted so that the stock estimate from \n",
    "    # the DSM for inflow from 2005-2015 is not much bigger than the total stock, \n",
    "    # which also comprises pre-2005 inflow data, which we don't have.\n",
    "    # Luxembourg: 16->12 years, Singapore and New Caledonia: 16->12 years, Saudi-Arabia: 12 years, \n",
    "    # Oman (stock unreasonably small), Cambodia (no stock data at all)\n",
    "    # These countries have either too small stocks reported or the lifetime for some of the 2005-2015 age-cohorts \n",
    "    # was much shorter than indicated in the parameter file, wich is possible, especially in rich countries, where\n",
    "    # vehicles get exported at young age.\n",
    "    # Apart from changing the lifetime distribution, no calibration was performed, and registration data were used instead.\n",
    "\n",
    "    # 1b) Estimate pre-2005 vehicle registration.\n",
    "    StockDiff_r = 1000 * ParameterDict['ODYM_Tutorial5_VehicleStock2015'].Values[0,region,25,0] - Dyn_MFA_EstimatedVehicleStock2015[region]\n",
    "    print('2015 stock difference before estimation of pre-2005 age-cohorts: ',StockDiff_r)\n",
    "    # estimate size of original inflow for countries where pre-2005 age-cohorts are >0 (applies to 124 out of 130 countries)\n",
    "    # Assumption: constant inflow for 15 years (1990-2004)\n",
    "    if StockDiff_r > 0:\n",
    "        Inflow_original = [StockDiff_r / 15 / DSM_Inflow.sf[25,i] for i in range(0,15)] # divide by value of survival function in 2015\n",
    "        PassengerVehicleFleet_MFA_System.ParameterDict['ODYM_Tutorial5_VehicleNewRegistration'].Values[0,region,0:15,0] = Inflow_original    \n",
    "    \n",
    "    # 1c) re-calculuate dynamic stock model with pre 2005 age-cohorts\n",
    "    DSM_Inflow = dsm.DynamicStockModel(t = np.array(IndexTable.Classification[IndexTable.index.get_loc('Time')].Items),\n",
    "                                       i = PassengerVehicleFleet_MFA_System.ParameterDict['ODYM_Tutorial5_VehicleNewRegistration'].Values[0,region,:,0], \n",
    "                                       lt = LT)\n",
    "    \n",
    "    Stock_by_cohort = DSM_Inflow.compute_s_c_inflow_driven()\n",
    "    #print(Stock_by_cohort.shape)\n",
    "    O_C = DSM_Inflow.compute_o_c_from_s_c()\n",
    "    #print(O_C.shape)\n",
    "    S = DSM_Inflow.compute_stock_total()\n",
    "    #print(S.shape)\n",
    "    DS = DSM_Inflow.compute_stock_change()\n",
    "    #print(DS.shape)\n",
    "    Dyn_MFA_EstimatedVehicleStock2015[region] = S[25]\n",
    "    StockDiff_r = 1000 * ParameterDict['ODYM_Tutorial5_VehicleStock2015'].Values[0,region,25,0] - Dyn_MFA_EstimatedVehicleStock2015[region]\n",
    "    print('2015 stock difference after estimation of pre-2005 age-cohorts: ',StockDiff_r)\n",
    "    print('')\n",
    "\n",
    "    # 1d) Multiply results with vehicle material content and assign to MFA system:\n",
    "    GlobalVehicleStock_TimeSeries[:,:,0,region] = Stock_by_cohort\n",
    "    GlobalEoL_Vehicles_TimeSeries[:,:,0,region] = O_C\n",
    "    \n",
    "    PassengerVehicleFleet_MFA_System.FlowDict['F_1_2'].Values[:,:,region,:,0] = \\\n",
    "    np.einsum('mgc,cg->cgm',ParameterDict['ODYM_Tutorial5_VehicleMaterialContent'].Values[:,:,region,:], \\\n",
    "    PassengerVehicleFleet_MFA_System.ParameterDict['ODYM_Tutorial5_VehicleNewRegistration'].Values[0,region,:,:]) / 1e9\n",
    "    # For the inflow, the age-cohort c is recorded in year t, and c = t.\n",
    "    # Here, region is not an index, as it is fixed, and the aspects process (U) and chemical element (e) are fixed \n",
    "    # because they are not listed explicitly in the material composition (e) and the flow dictionary (U).\n",
    "    \n",
    "    PassengerVehicleFleet_MFA_System.FlowDict['F_2_3'].Values[:,:,:,region,:,0] = \\\n",
    "    np.einsum('mgc,tc->tcgm',ParameterDict['ODYM_Tutorial5_VehicleMaterialContent'].Values[:,:,region,:],O_C) / 1e9\n",
    "    \n",
    "    PassengerVehicleFleet_MFA_System.StockDict['S_2'].Values[:,:,:,region,:,0] = \\\n",
    "    np.einsum('mgc,tc->tcgm',ParameterDict['ODYM_Tutorial5_VehicleMaterialContent'].Values[:,:,region,:],Stock_by_cohort) / 1e9\n",
    "    \n",
    "    PassengerVehicleFleet_MFA_System.StockDict['dS_2'].Values[:,:,region,:,0] = \\\n",
    "    np.einsum('mgc,c->cgm',ParameterDict['ODYM_Tutorial5_VehicleMaterialContent'].Values[:,:,region,:],DS) / 1e9\n",
    "    # For the net stock change, the age-cohort c is recorded in year t, and c = t.\n",
    "    \n",
    "# Compare stock estimated by DSM with reported stock for 2015\n",
    "# and plot stock difference for all countries, after calibration:\n",
    "#StockDiff = 1000 * ParameterDict['ODYM_Tutorial5_VehicleStock2015'].Values[0,:,25,0] - Dyn_MFA_EstimatedVehicleStock2015\n",
    "#print('')\n",
    "#print('Difference between reported stock and estimated remainder from 2005-2015 age-cohorts: ')\n",
    "#print(list(zip(IndexTable.Classification[IndexTable.set_index('IndexLetter').index.get_loc('r')].Items,StockDiff.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UncParts   = ParameterDict['ODYM_Tutorial5_VehicleLifetime'].Uncert[region*Nt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a second step, we compute the available scrap and the remaining flows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PassengerVehicleFleet_MFA_System.FlowDict['F_0_1'].Values = np.einsum('tgrme->tgme',PassengerVehicleFleet_MFA_System.FlowDict['F_1_2'].Values)\n",
    "\n",
    "PassengerVehicleFleet_MFA_System.FlowDict['F_3_4'].Values = np.einsum('gmw,tcgrme->twme',ParameterDict['ODYM_Tutorial5_EoLRecoveryRate'].Values,PassengerVehicleFleet_MFA_System.FlowDict['F_2_3'].Values)\n",
    "PassengerVehicleFleet_MFA_System.FlowDict['F_4_0'].Values = PassengerVehicleFleet_MFA_System.FlowDict['F_3_4'].Values\n",
    "\n",
    "PassengerVehicleFleet_MFA_System.FlowDict['F_3_0'].Values = np.einsum('tcgrme->tme',PassengerVehicleFleet_MFA_System.FlowDict['F_2_3'].Values) - np.einsum('twme->tme',PassengerVehicleFleet_MFA_System.FlowDict['F_3_4'].Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mass balance check:\n",
    "Bal = PassengerVehicleFleet_MFA_System.MassBalance()\n",
    "print(Bal.shape) # dimensions of balance are: time step x process x chemical element\n",
    "print(np.abs(Bal).sum(axis = 0)) # reports the sum of all absolute balancing errors by process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of results, short, because we will focus on the Monte-Carlo Simulation later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MatStock_trm         = np.einsum('tcrgme->trm',PassengerVehicleFleet_MFA_System.StockDict['S_2'].Values)\n",
    "MatStock_2017_global = np.einsum('rm->m',MatStock_trm[27,:,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Material stock in Mt, 2017, global')\n",
    "[print(i) for i in list(zip(IndexTable.Classification[IndexTable.set_index('IndexLetter').index.get_loc('m')].Items,MatStock_2017_global))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figures above provide a preliminary answer to the first research question: _How big is the material stock currently embodied in the global passenger vehicle fleet?_\n",
    "The answer is preliminary, because the variability of the metal composition of the individual car and thus the uncertainty of aggregate total metal content is quite high for some metals, and we need to quantify the uncertainty ranges using a Monte-Carlo-Simulation in the next section.\n",
    "\n",
    "Here, we will answer the second question: _When will this material become available for recycling?_\n",
    "The time frame of the considered historic vehicle registration is 1990-2017, but we extended the model time frame until 2050 but with zero new registration after 2017. That means, that the calculated future scrap flows result from the 2017 stock only and can be extracted directly to answer the second question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future material outflow by year (t), region (r), and material (m):\n",
    "Future_Material_Outflow_trm = np.einsum('tcrm->trm',PassengerVehicleFleet_MFA_System.FlowDict['F_2_3'].Values[28::,:,0,:,:,0])\n",
    "\n",
    "# Future srap flow by year (t) and scrap type (w):\n",
    "Future_Scrap_Availability_tm = np.einsum('twme->tw',PassengerVehicleFleet_MFA_System.FlowDict['F_4_0'].Values[28::,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future_Material_Outflow_trm can now be analysed for certain regions, e.g. for industries and policy makers to understand which materials will be available in which quantities and when. Since the model tracks different age-cohorts, one can in principle also quantify the outflow of individual age-cohorts, e.g., when they contain certain alloys or contaminants. Here, we focus on the estimation of the scrap flows from the 2017 vehicle fleet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.set_loglevel(\"info\") \n",
    "\n",
    "width = 35\n",
    "height = 25\n",
    "\n",
    "WasteGroups    = IndexTable.Classification[IndexTable.set_index('IndexLetter').index.get_loc('w')].Items\n",
    "WasteGroups[1] = 'Al extrusion scrap'\n",
    "WasteGroups[5] = 'Shredder light fraction'\n",
    "MyColorCycle = pylab.cm.Paired(np.arange(0,1,0.1)) # select 10 colors from the 'Paired' color map.\n",
    "\n",
    "# plot at linear scale\n",
    "fig, ax = plt.subplots()\n",
    "plt.figure(figsize=(width, height))\n",
    "for m in range(0,len(WasteGroups)):\n",
    "    ax.plot(PassengerVehicleFleet_MFA_System.IndexTable['Classification']['Time'].Items[28::], \n",
    "            Future_Scrap_Availability_tm[:,m],\n",
    "            color = MyColorCycle[m,:], linewidth = 2)\n",
    "ax.set_ylabel('Scrap flows, Mt/yr,',fontsize =16)\n",
    "ax.legend(WasteGroups, loc='upper right',prop={'size':8})\n",
    "fig.savefig('ScrapFlows_2017', dpi = 400)  \n",
    "\n",
    "# plot at log scale\n",
    "fig, ax = plt.subplots()\n",
    "plt.figure(figsize=(width, height))\n",
    "for m in range(0,len(WasteGroups)):\n",
    "    ax.semilogy(PassengerVehicleFleet_MFA_System.IndexTable['Classification']['Time'].Items[28::], \n",
    "            Future_Scrap_Availability_tm[:,m],\n",
    "            color = MyColorCycle[m,:], linewidth = 2)\n",
    "ax.set_ylabel('Scrap flows, Mt/yr,',fontsize =16)\n",
    "ax.legend(WasteGroups, loc='upper right',prop={'size':8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that the pre-2020 outflows will decline sharply by about 25%, before they reach a plateau between ca. 2021 and 2029. This plateau is probably the consequence of two peaks overlapping, one pre-2017 peak (from 2002 +/- 5 years cars) and one ca. 2027 (from 2012 +/- 5 years cars). To find out which countries are causing this behaviour, let' zoom into the region-specific results! The value for electronic waste is very low because due to data limitations, it was assumed that all copper goes into the copper wire scrap fraction and all plastic to the shredder light fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.set_loglevel(\"info\") \n",
    "\n",
    "width = 35\n",
    "height = 25\n",
    "\n",
    "# We want to plot the ten countries with the largest EoL vehicle flows in 2020:\n",
    "Sort = np.argsort(Future_Material_Outflow_trm[2,:,:].sum(axis =1)) \n",
    "Top10 = [i for i in reversed(Sort[-10::])]\n",
    "\n",
    "Top10Regions = [IndexTable.Classification[IndexTable.set_index('IndexLetter').index.get_loc('r')].Items[i] for i in Top10]\n",
    "MyColorCycle = pylab.cm.Paired(np.arange(0,1,0.1)) # select 10 colors from the 'Paired' color map.\n",
    "fig, ax = plt.subplots()\n",
    "plt.figure(figsize=(width, height))\n",
    "for m in range(0,len(Top10)):\n",
    "    ax.plot(PassengerVehicleFleet_MFA_System.IndexTable['Classification']['Time'].Items[28::], \n",
    "            Future_Material_Outflow_trm[:,Top10[m],:].sum(axis =1),\n",
    "            color = MyColorCycle[m,:], linewidth = 2)\n",
    "ax.set_ylabel('Scrap flows, Mt/yr,',fontsize =16)\n",
    "ax.legend(Top10Regions, loc='upper right',prop={'size':8})\n",
    "fig.savefig('ScrapFlows_2017_Top10Regions', dpi = 400)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total outflow from the 2017 stock is indeed the consequence of two overlapping peaks, one resulting from the constantly high car sales in the richest countries, and the later one resulting from the recent sharp increase of vehicle registration in China."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6) Performing a Monte-Carlo-Simulation\n",
    "\n",
    "ODYM has no built-in MC tool yet, as practices still need to evolve and the different application cases vary a lot.\n",
    "Re-sampling an entire parameter from the Uncertainty information is easy to implement but often very inefficient, as, like in this case, few actually known parameter values are replicated to span all countries and age-cohorts.\n",
    "\n",
    "Here, we therefore sample the 25 original material content array only, and replicate the sampled values to cover all regions and age-cohorts. Of course, this can be changed when more data is available. We sample the material content per vehicle NMC times from its defined distribution and re-calculate the stock and outflow variables.\n",
    "\n",
    "The result can be visualized in box plots, for example, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mylog.info('### 6 - Performing a Monte-Carlo-Simulation')\n",
    "\n",
    "NMC                = 2000 # Number of Monte-Carlo runs\n",
    "MatContent_Samples = np.zeros((NMC,NM)) # define sample array for material content\n",
    "MatStock_2017_MC   = np.zeros((NMC,NM)) # define sample array for material stock\n",
    "MatOFlow_2017_MC   = np.zeros((NMC,NM)) # define sample array for material in EoL vehicles\n",
    "\n",
    "# 1) re-sample the material composition\n",
    "for m in range(0,NM):\n",
    "    UncParts = ParameterDict['ODYM_Tutorial5_VehicleMaterialContent'].Uncert[m*Nt*NR +20].split(';') # parse uncertainty string for material m\n",
    "    print(UncParts)\n",
    "    MatContent_Samples[:,m] = np.random.uniform(float(UncParts[1]),float(UncParts[2]),NMC)\n",
    "\n",
    "# 2) re-calculate the material stock and the outflow\n",
    "print('')\n",
    "for s in range(0,NMC):\n",
    "    if s % 100 == 0:\n",
    "        print(s)\n",
    "    # 2a) Replicate vehicle material content for all countries and age-cohorts\n",
    "    ParameterDict['ODYM_Tutorial5_VehicleMaterialContent'].Values[:,0,:,:] = np.einsum('m,rc->mrc',MatContent_Samples[s,:],np.ones((NR,Nt)))\n",
    "    # 2b) Assign aggregated result to result array:\n",
    "    MatStock_2017_MC[s,:] = np.einsum('mgrc,cgr->m',ParameterDict['ODYM_Tutorial5_VehicleMaterialContent'].Values,GlobalVehicleStock_TimeSeries[27,:,:,:]) / 1e9\n",
    "    MatOFlow_2017_MC[s,:] = np.einsum('mgrc,cgr->m',ParameterDict['ODYM_Tutorial5_VehicleMaterialContent'].Values,GlobalEoL_Vehicles_TimeSeries[27,:,:,:]) / 1e9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.set_loglevel(\"info\") \n",
    "\n",
    "# Steel only (largest by far)\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(MatStock_2017_MC[:,0], notch=True)\n",
    "ax.set_title('Variation of material content, steel, in Mt, for 2017 stock.')\n",
    "ax.set_xticklabels([IndexTable.Classification[IndexTable.set_index('IndexLetter').index.get_loc('m')].Items[0]], fontsize =14)\n",
    "fig.savefig('BoxPlot_Steel_2017', dpi = 400)   \n",
    "\n",
    "# Selected materials (largest second to steel)\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(MatStock_2017_MC[:,[1,2,4,11,13,19,20,21,24]], notch=True)\n",
    "ax.set_title('Variation of material content, in Mt, for 2017 stock.')\n",
    "PLabels = [IndexTable.Classification[IndexTable.set_index('IndexLetter').index.get_loc('m')].Items[i] for i in[1,2,4,11,13,19,20,21,24]]\n",
    "PLabels[1] = 'Copper'\n",
    "ax.set_xticklabels(PLabels, fontsize =12, rotation =90)\n",
    "fig.savefig('BoxPlot_OtherMaterials_2017_Sel', dpi = 400, bbox_inches='tight')  \n",
    "\n",
    "# All materials (other than steel)\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(MatStock_2017_MC[:,1::], notch=True)\n",
    "ax.set_title('Variation of material content, in Mt, for 2017 stock.')\n",
    "fig.savefig('BoxPlot_OtherMaterials_2017', dpi = 400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the material content array comes with min/max uncertainty/variability ranges, from which uniformly distributed samples were drawn, the box plot shows no outliers and the 1./3. quartiles span exactly half the space between min and max values. It does show how the variability of the different material content estimates impacts the variation of the material stock estimate. While the estimates for materials 20-22 (rubber, glass, and ceramics) are rather certain, the one for material 11 (Aluminium) varies substantially, which reflects the high variability of the Al content of passenger vehicles.\n",
    "\n",
    "If the data are well structured and the model is set up accordingly, performing an uncertainty analysis can be quickly done, as the brevity of the Monte-Carlo-code above shows. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 7) Exporting results and close model calculation\n",
    "\n",
    "It is good practice to export the data behind all figures plotted and those shown in large tables so that other researchers can easily look them up and re-use them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define excel export function\n",
    "def ExcelSheetFill(Workbook, Sheetname, values, topcornerlabel=None,\n",
    "                   rowlabels=None, collabels=None, Style=None,\n",
    "                   rowselect=None, colselect=None):\n",
    "    Sheet = Workbook.add_sheet(Sheetname)\n",
    "    if topcornerlabel is not None:\n",
    "        if Style is not None:\n",
    "            Sheet.write(0,0,label = topcornerlabel, style = Style)  # write top corner label\n",
    "        else:\n",
    "            Sheet.write(0,0,label = topcornerlabel)  # write top corner label\n",
    "    if rowselect is None: # assign row select if not present (includes all rows in that case)\n",
    "        rowselect = np.ones((values.shape[0]))\n",
    "    if colselect is None: # assign col select if not present (includes all columns in that case)\n",
    "        colselect = np.ones((values.shape[1]))        \n",
    "    if rowlabels is not None: # write row labels\n",
    "         rowindexcount = 0\n",
    "         for m in range(0,len(rowlabels)):\n",
    "             if rowselect[m] == 1: # True if True or 1\n",
    "                 if Style is None:\n",
    "                     Sheet.write(rowindexcount +1, 0, label = rowlabels[m])\n",
    "                 else:\n",
    "                     Sheet.write(rowindexcount +1, 0, label = rowlabels[m], style = Style)\n",
    "                 rowindexcount += 1\n",
    "    if collabels is not None: # write column labels\n",
    "         colindexcount = 0\n",
    "         for m in range(0,len(collabels)):\n",
    "             if colselect[m] == 1: # True if True or 1\n",
    "                 if Style is None:\n",
    "                     Sheet.write(0, colindexcount +1, label = collabels[m])\n",
    "                 else:\n",
    "                     Sheet.write(0, colindexcount +1, label = collabels[m], style = Style)\n",
    "                 colindexcount += 1   \n",
    "    # write values:\n",
    "    rowindexcount = 0\n",
    "    for m in range(0,values.shape[0]): # for all rows\n",
    "        if rowselect[m] == 1:\n",
    "            colindexcount = 0\n",
    "            for n in range(0,values.shape[1]): # for all columns\n",
    "                if colselect[n] == 1:\n",
    "                    Sheet.write(rowindexcount +1, colindexcount + 1, label=values[m, n])\n",
    "                    colindexcount += 1\n",
    "            rowindexcount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mylog.info('### 7 - Exporting results and close model calculation')\n",
    "#Export to Excel\n",
    "\n",
    "myfont = xlwt.Font()\n",
    "myfont.bold = True\n",
    "mystyle = xlwt.XFStyle()\n",
    "mystyle.font = myfont\n",
    "Result_workbook = xlwt.Workbook(encoding = 'ascii') # Export element stock by region\n",
    "\n",
    "#scrap supply, global total, by scrap type:\n",
    "ExcelSheetFill(Result_workbook, 'F_4_0_Scrap_Supply_types', Future_Scrap_Availability_tm, topcornerlabel = 'F_4_0: Future scrap availability, by year and scrap group, Mt/yr', rowlabels = IndexTable.Classification[IndexTable.set_index('IndexLetter').index.get_loc('t')].Items[28::], collabels = IndexTable.Classification[IndexTable.set_index('IndexLetter').index.get_loc('w')].Items, Style = mystyle, rowselect = None, colselect = None)\n",
    "#material outflow, top 10 countries, all scrap types:\n",
    "ExcelSheetFill(Result_workbook, 'F_2_3_EoL_Material_region', Future_Material_Outflow_trm[:,Top10,:].sum(axis =2), topcornerlabel = 'F_2_3: Future EoL vehicle material flows, by year and region, Mt/yr', rowlabels = IndexTable.Classification[IndexTable.set_index('IndexLetter').index.get_loc('t')].Items[28::], collabels = Top10Regions, Style = mystyle, rowselect = None, colselect = None)\n",
    "\n",
    "# The Monte-Carlo simulation result can be exported as well but is not exported here to keep the resulting Excel file small.\n",
    "\n",
    "Result_workbook.save('ODYM_GlobalVehicleFleet_Results.xls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close log file\n",
    "\n",
    "Mylog.info('Script is finished. Terminating logging process and closing all log files.')\n",
    "\n",
    "# remove all handlers from logger\n",
    "root = log.getLogger()\n",
    "root.handlers = []  # required if you don't want to exit the shell\n",
    "log.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
